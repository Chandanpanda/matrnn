{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tianlechen/Documents/GitHub/Togepi/tianle-rxplenishment/gru_arrivaltimes/run_crusoely/blagdon_sodapop_jointwrfm\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2 as pg\n",
    "\n",
    "pklhp = pickle.HIGHEST_PROTOCOL\n",
    "\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "print (cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source transactions of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skusfname: sodapopskus.txt\n",
      "timeunit: week\n",
      "      custid  ordqty  product_sku                date\n",
      "0  9623203.0     2.0      10201.0 2013-02-09 20:20:47\n",
      "1  9475196.0     1.0      10201.0 2013-01-08 14:16:45\n",
      "2   524466.0     1.0      10201.0 2013-01-08 13:39:34\n",
      "3  7646254.0     2.0      10201.0 2013-03-05 17:13:34\n",
      "4  9074093.0     1.0      10201.0 2014-06-04 13:39:00\n"
     ]
    }
   ],
   "source": [
    "import funforsql as ffs\n",
    "alltrans = ffs.gettransactions()\n",
    "if testing: print (alltrans.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tstart:\t2014-01-01 00:00:00\n",
      "ttrain:\t2015-06-30 00:00:00\n",
      "tend:\t2016-12-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "d = pickle.load(gzip.open('dates.pkl' + str(pklhp), 'rb'))\n",
    "if testing: \n",
    "    for k in d:\n",
    "        print ('%s:\\t%s' % (k, d[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intraining = alltrans['date'] >= d['tstart']\n",
    "intraining = np.logical_and(intraining, alltrans['date'] <= d['tend'])\n",
    "alltrans = alltrans.loc[intraining, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len alltrans 2042361\n"
     ]
    }
   ],
   "source": [
    "if testing: print ('len alltrans', len(alltrans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            custid  ordqty  product_sku                date\n",
      "40776    9314863.0     1.0      64330.0 2014-01-01 09:21:16\n",
      "58099   12698719.0     2.0     181042.0 2014-01-01 09:29:13\n",
      "792836   8367321.0     2.0      83092.0 2014-01-01 09:52:32\n",
      "61724   11020411.0     4.0     140363.0 2014-01-01 10:10:41\n",
      "62444   10199683.0     1.0     140363.0 2014-01-01 10:14:52\n"
     ]
    }
   ],
   "source": [
    "if testing: print (alltrans.sort_values(by = 'date').head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up some global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def datestrrep(dt):\n",
    "    return str(dt.strftime('%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len unique allcids 596811\n"
     ]
    }
   ],
   "source": [
    "allcids = np.unique(np.array(alltrans['custid']))\n",
    "if testing: print ('len unique allcids', len(allcids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  10201.   37852.   64330.   83092.  120768.  137538.  140363.  181042.]\n"
     ]
    }
   ],
   "source": [
    "allskus = np.sort(np.unique(np.array(alltrans.loc[:, 'product_sku'])))\n",
    "if testing: print (allskus); print('len(allskus):', len(allskus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len alltimes 1096\n"
     ]
    }
   ],
   "source": [
    "alltimes = pd.date_range(d['tstart'], d['tend'])\n",
    "if testing: print ('len alltimes', len(alltimes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source an rfm file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getrfm(valdate, verbose = False):\n",
    "    fname = cwd + '/rfmcache/rfm_valdate_%s.pkl2' % str(datestrrep(valdate))\n",
    "    if verbose: import time; t0 = time.time()\n",
    "    if pklhp == 2:\n",
    "        out = pickle.load(gzip.open(fname, 'rb'))\n",
    "    else:\n",
    "        out = pickle.load(gzip.open(fname, 'rb'), encoding = 'latin1')\n",
    "    if verbose: print ('loading took', time.time()-t0)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len x: 10\n"
     ]
    }
   ],
   "source": [
    "if testing:\n",
    "    x = getrfm(alltimes[0])\n",
    "    print ('len x:', len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up target cids, times, skus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "tgtcids = allcids\n",
    "if testing: \n",
    "    tgtcids = allcids[:10]\n",
    "    print (len(tgtcids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "tgttimes = alltimes\n",
    "if testing: \n",
    "    tgttimes = alltimes[:100]\n",
    "    print (len(tgttimes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10201.  37852.]\n"
     ]
    }
   ],
   "source": [
    "tgtskus = allskus\n",
    "if testing:\n",
    "    tgtskus = allskus[:2]\n",
    "    print (tgtskus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to get all covariates for tgtcids, tgtskus, tgttimes\n",
    "\n",
    "data matrix is of shape:\n",
    "```\n",
    "len(tgtcids) BY len(tgtskus) BY len(tgttimes) BY 13\n",
    "```\n",
    "\n",
    "since there are 13 covariates:\n",
    "```\n",
    "(tse, tte, unc, pcs), 3*(rfmall, rfmcat, rfmthis)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(tgtcids):10, len(tgtskus):2, len(tgttimes):100\n",
      "max size in MB: 0.064\n"
     ]
    }
   ],
   "source": [
    "print ('len(tgtcids):%s, len(tgtskus):%s, len(tgttimes):%s' % (len(tgtcids), len(tgtskus), len(tgttimes)))\n",
    "print ('max size in MB:', 32*np.prod((len(tgtcids), len(tgtskus), len(tgttimes)))/np.power(10,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import TimeSeriesTransforms as tstf\n",
    "\n",
    "def formattedrow(cidtemp, skutemp, tgttimes, verbose = False):\n",
    "    '''\n",
    "    returns np.array of shape (len(tgttimes), 13)\n",
    "    where 13 = #(tse,tte,unc,pcs) + 3*#(rfmall,rfmcat,rfmthis)\n",
    "    '''\n",
    "    if verbose: import time\n",
    "    \n",
    "    skuindex = int(np.where(allskus == skutemp)[0])\n",
    "    \n",
    "    if verbose: t0 = time.time()\n",
    "    # get event indicator for cidtemp, skutemp\n",
    "    evtind = alltrans['custid'] == cidtemp\n",
    "    evtind = np.logical_and(evtind, alltrans['product_sku'] == skutemp)\n",
    "    # event times as number of days from (origin = min(tgttimes))\n",
    "    evt = np.sort(np.array((alltrans.loc[evtind, 'date'] - min(tgttimes)).dt.days))\n",
    "    evt = evt[evt < len(tgttimes)]\n",
    "\n",
    "    # default is uncensored=False, purchstatus=False, eventindicator=False\n",
    "    evind = np.zeros(len(tgttimes))\n",
    "    unc   = np.zeros(len(tgttimes))\n",
    "    pcs   = np.zeros(len(tgttimes))\n",
    "    # if there has been an event...\n",
    "    if len(evt) > 0:\n",
    "        evind[evt] = 1\n",
    "        unc[:max(evt)] = 1\n",
    "        pcs[min(evt):] = 1\n",
    "    # transform to get tse, tte\n",
    "    tse = tstf.tse(evind); tte = tstf.tte(evind)\n",
    "    # reshape so that is of shape (len(tgttimes), 1)\n",
    "    tse = tse.reshape((len(tgttimes), 1))\n",
    "    tte = tte.reshape((len(tgttimes), 1))\n",
    "    unc = unc.reshape((len(tgttimes), 1))\n",
    "    pcs = pcs.reshape((len(tgttimes), 1))\n",
    "    if verbose: t1 = time.time(); print('(tse, tte, unc, pcs) done in:', t1-t0); t0 = t1\n",
    "    \n",
    "    # set up rfms\n",
    "    rfmm = np.zeros((len(tgttimes), 3, 3))\n",
    "    for t in range(len(tgttimes)):\n",
    "        x = getrfm(tgttimes[t], verbose = verbose)\n",
    "        rfmall = x[0]\n",
    "        rfmcat = x[1]\n",
    "        rfmsku = x[skuindex+2]\n",
    "        rfmlevel = 0\n",
    "        for rfmtemp in [rfmall, rfmcat, rfmsku]:\n",
    "            cidind = rfmtemp['custid'] == cidtemp\n",
    "            if np.any(cidind):\n",
    "                rfmm[t, rfmlevel, :] = np.array(rfmtemp.loc[cidind, ['r', 'f', 'm']]).reshape((1, 1, 3))\n",
    "            rfmlevel += 1\n",
    "    if verbose: t1 = time.time(); print('rfm source and stuff done in:', t1-t0); t0 = t1\n",
    "            \n",
    "    # flatten rfm\n",
    "    rfmm_rs = rfmm.reshape((len(tgttimes), 9))\n",
    "    # concatenate all and return\n",
    "    collection = (tse, tte, unc, pcs, rfmm_rs)\n",
    "    rowtemp = np.concatenate(collection, axis = 1)\n",
    "    return rowtemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def formattedrow_allskus(cidtemp, tgtskus, tgttimes, verbose = False):\n",
    "    '''\n",
    "    return long version of formattedrow, done for all in tgtskus\n",
    "    '''\n",
    "    longshape = (1, 1, len(tgttimes), 13)\n",
    "    def worker(skutemp): \n",
    "        out = formattedrow(cidtemp, skutemp, tgttimes, verbose = verbose)\n",
    "        return out.reshape(longshape)\n",
    "        \n",
    "    return np.concatenate([worker(k) for k in tgtskus], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benchmarking for one cid...\n",
      "(tse, tte, unc, pcs) done in: 0.016637802124023438\n",
      "rfm source and stuff done in: 42.918596029281616\n",
      "(tse, tte, unc, pcs) done in: 0.007244110107421875\n",
      "rfm source and stuff done in: 42.55528497695923\n",
      "85.50242829322815\n"
     ]
    }
   ],
   "source": [
    "if testing:\n",
    "    import time\n",
    "    print ('benchmarking for one cid...')\n",
    "    t0 = time.time()\n",
    "    out = formattedrow_allskus(tgtcids[0], tgtskus, tgttimes, verbose = True)\n",
    "    print (time.time() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimates for runtimes...\n",
    "```\n",
    "for nseq=100, nskus=2, timed=100s\n",
    "for nseq=1000, nskus=8, expect=4000s\n",
    "```\n",
    "Repeat this for...\n",
    "```\n",
    "nids=600,000\n",
    "nthreads=4: expect=4000*600,000/4=20yrs\n",
    "nthreads=24: expect=4000*600,000/24=3yrs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing cid: 28.0\n",
      "doing cid: 51.0\n",
      "doing cid: 68.0\n",
      "doing cid: 39.0\n",
      "doing cid: 70.0\n",
      "doing cid: 152.0\n",
      "doing cid: 101.0\n",
      "doing cid: 157.0\n",
      "doing cid: 163.0\n",
      "doing cid: 190.0\n"
     ]
    }
   ],
   "source": [
    "def worker(cidtemp):\n",
    "    ''' wrapper for formattedrow_allskus for use in Pool.map'''\n",
    "    print ('doing cid: %s' % cidtemp)\n",
    "    return formattedrow_allskus(cidtemp, tgtskus, tgttimes)\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "nthreads = 24\n",
    "if testing: nthreads = 2\n",
    "\n",
    "p = Pool(nthreads)\n",
    "resl = p.map(worker, tgtcids)\n",
    "data = np.concatenate(resl, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2, 100, 13)\n"
     ]
    }
   ],
   "source": [
    "if testing: print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = 'data.pkl' + str(pklhp)\n",
    "pickle.dump(data, gzip.open(fname, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected file sizes...\n",
    "\n",
    "```\n",
    "len(tgtcids):10, len(tgtskus):2, len(tgttimes):100\n",
    "max size in MB: 0.064\n",
    "actual size on disk in MB: 0.009\n",
    "\n",
    "len(tgtcids):600,000, len(tgtskus):8, len(tgttimes):1,000\n",
    "max size in MB: 153,600\n",
    "expect size on disk in MB: 21,600\n",
    "\n",
    "len(tgtcids):1,000, len(tgtskus):8, len(tgttimes):1,000\n",
    "max size in MB: 256\n",
    "expect size on disk in MB: 36\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
