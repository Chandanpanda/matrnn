{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tianlechen/Documents/GitHub/Togepi/tianle-rxplenishment/gru_arrivaltimes/run_crusoely/blagdon_sodapop_jointwrfm\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2 as pg\n",
    "\n",
    "pklhp = pickle.HIGHEST_PROTOCOL\n",
    "\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "print (cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source transactions of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skusfname: sodapopskus.txt\n",
      "timeunit: week\n",
      "      custid  ordqty  product_sku                date\n",
      "0  9623203.0     2.0      10201.0 2013-02-09 20:20:47\n",
      "1  9475196.0     1.0      10201.0 2013-01-08 14:16:45\n",
      "2   524466.0     1.0      10201.0 2013-01-08 13:39:34\n",
      "3  7646254.0     2.0      10201.0 2013-03-05 17:13:34\n",
      "4  9074093.0     1.0      10201.0 2014-06-04 13:39:00\n"
     ]
    }
   ],
   "source": [
    "import funforsql as ffs\n",
    "alltrans = ffs.gettransactions()\n",
    "if testing: print (alltrans.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tstart:\t2014-01-01 00:00:00\n",
      "ttrain:\t2015-06-30 00:00:00\n",
      "tend:\t2016-12-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "d = pickle.load(gzip.open('dates.pkl' + str(pklhp), 'rb'))\n",
    "if testing: \n",
    "    for k in d:\n",
    "        print ('%s:\\t%s' % (k, d[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intraining = alltrans['date'] >= d['tstart']\n",
    "intraining = np.logical_and(intraining, alltrans['date'] <= d['ttrain'])\n",
    "alltrans = alltrans.loc[intraining, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len alltrans 1017710\n"
     ]
    }
   ],
   "source": [
    "if testing: print ('len alltrans', len(alltrans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            custid  ordqty  product_sku                date\n",
      "40776    9314863.0     1.0      64330.0 2014-01-01 09:21:16\n",
      "58099   12698719.0     2.0     181042.0 2014-01-01 09:29:13\n",
      "792836   8367321.0     2.0      83092.0 2014-01-01 09:52:32\n",
      "61724   11020411.0     4.0     140363.0 2014-01-01 10:10:41\n",
      "62444   10199683.0     1.0     140363.0 2014-01-01 10:14:52\n"
     ]
    }
   ],
   "source": [
    "if testing: print (alltrans.sort_values(by = 'date').head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up some global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def datestrrep(dt):\n",
    "    return str(dt.strftime('%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len unique allcids 341957\n"
     ]
    }
   ],
   "source": [
    "allcids = np.unique(np.array(alltrans['custid']))\n",
    "print ('len unique allcids', len(allcids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  10201.   37852.   64330.   83092.  120768.  137538.  140363.  181042.]\n",
      "len(allskus): 8\n"
     ]
    }
   ],
   "source": [
    "allskus = np.sort(np.unique(np.array(alltrans.loc[:, 'product_sku'])))\n",
    "print (allskus)\n",
    "print('len(allskus):', len(allskus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len alltimes 157\n",
      "DatetimeIndex(['2014-01-01', '2014-01-08', '2014-01-15', '2014-01-22',\n",
      "               '2014-01-29', '2014-02-05', '2014-02-12', '2014-02-19',\n",
      "               '2014-02-26', '2014-03-05'],\n",
      "              dtype='datetime64[ns]', freq='7D')\n",
      "DatetimeIndex(['2016-10-26', '2016-11-02', '2016-11-09', '2016-11-16',\n",
      "               '2016-11-23', '2016-11-30', '2016-12-07', '2016-12-14',\n",
      "               '2016-12-21', '2016-12-28'],\n",
      "              dtype='datetime64[ns]', freq='7D')\n"
     ]
    }
   ],
   "source": [
    "alltimes = pickle.load(gzip.open('rfmcache_alltimes.pkl' + str(pklhp), 'rb'))\n",
    "print ('len alltimes', len(alltimes))\n",
    "print (alltimes[:10])\n",
    "print (alltimes[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source an rfm file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getrfm(valdate, verbose = False):\n",
    "    fname = cwd + '/rfmcache/rfm_valdate_%s.pkl2' % str(datestrrep(valdate))\n",
    "    if verbose: import time; t0 = time.time()\n",
    "    if pklhp == 2:\n",
    "        out = pickle.load(gzip.open(fname, 'rb'))\n",
    "    else:\n",
    "        out = pickle.load(gzip.open(fname, 'rb'), encoding = 'latin1')\n",
    "    if verbose: print ('loading took', time.time()-t0)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if testing:\n",
    "    x = getrfm(alltimes[0])\n",
    "    print ('len x:', len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up target cids, times, skus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgtcids = allcids\n",
    "if testing: \n",
    "    tgtcids = allcids[:8]\n",
    "    print (len(tgtcids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgttimes = alltimes\n",
    "if testing: \n",
    "    tgttimes = alltimes[:100]\n",
    "    print (len(tgttimes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgtskus = allskus\n",
    "if testing:\n",
    "    tgtskus = allskus[:2]\n",
    "    print (tgtskus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to get all covariates for tgtcids, tgtskus, tgttimes\n",
    "\n",
    "data matrix is of shape:\n",
    "```\n",
    "len(tgtcids) BY len(tgtskus) BY len(tgttimes) BY 13\n",
    "```\n",
    "\n",
    "since there are 13 covariates:\n",
    "```\n",
    "(tse, tte, unc, pcs), 3*(rfmall, rfmcat, rfmthis)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import TimeSeriesTransforms as tstf\n",
    "\n",
    "def formattedrow_tstf(cidtemp, skutemp, tgttimes, verbose = False):\n",
    "    '''\n",
    "    returns np.array of shape (len(tgttimes), 4)\n",
    "    where 4 = #(tse,tte,unc,pcs)\n",
    "    '''\n",
    "    if verbose: import time\n",
    "    \n",
    "    skuindex = int(np.where(allskus == skutemp)[0])\n",
    "    \n",
    "    if verbose: t0 = time.time()\n",
    "    # get event indicator for cidtemp, skutemp\n",
    "    evtind = alltrans['custid'] == cidtemp\n",
    "    evtind = np.logical_and(evtind, alltrans['product_sku'] == skutemp)\n",
    "    # event times as number of 7days from (origin = min(tgttimes))\n",
    "    evt = alltrans.loc[evtind, 'date']\n",
    "    evt = evt[evt <= max(tgttimes)]\n",
    "    evt = np.sort(np.floor_divide(np.array((evt - min(tgttimes)).dt.days), 7))\n",
    "\n",
    "    # default is uncensored=False, purchstatus=False, eventindicator=False\n",
    "    evind = np.zeros(len(tgttimes))\n",
    "    unc   = np.zeros(len(tgttimes))\n",
    "    pcs   = np.zeros(len(tgttimes))\n",
    "    # if there has been an event...\n",
    "    if len(evt) > 0:\n",
    "        # update the indicators\n",
    "        evind[evt] = 1\n",
    "        unc[:max(evt)] = 1\n",
    "        pcs[min(evt):] = 1\n",
    "    # transform to get tse, tte\n",
    "    tse = tstf.tse(evind)\n",
    "    tte = tstf.tte(evind)\n",
    "    # reshape so that is of shape (len(tgttimes), 1)\n",
    "    tse = tse.reshape((len(tgttimes), 1))\n",
    "    tte = tte.reshape((len(tgttimes), 1))\n",
    "    unc = unc.reshape((len(tgttimes), 1))\n",
    "    pcs = pcs.reshape((len(tgttimes), 1))\n",
    "    if verbose: t1 = time.time(); print('(tse, tte, unc, pcs) done in:', t1-t0); t0 = t1\n",
    "    \n",
    "    return np.concatenate((tse, tte, unc, pcs), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def formattedrow_allskus(cidtemp, tgtskus, tgttimes, verbose = False):\n",
    "    '''\n",
    "    return long version of formattedrow_tstf, done for all in tgtskus\n",
    "    '''\n",
    "    longshape = (1, len(tgttimes), 1, 4)\n",
    "    def worker(skutemp): \n",
    "        out = formattedrow_tstf(cidtemp, skutemp, tgttimes, verbose = verbose)\n",
    "        return out.reshape(longshape)\n",
    "    return np.concatenate([worker(k) for k in tgtskus], axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getrfm_matrix(tgtcids, rfmtemp, verbose = False):\n",
    "    '''\n",
    "    return (len(tgtcids), 3)\n",
    "    where #(r, f, m) = 3\n",
    "    '''\n",
    "    out = np.zeros((len(tgtcids), 3))\n",
    "    if verbose: import time; t0 = time.time()\n",
    "    for i in range(len(tgtcids)):\n",
    "        cidtemp = tgtcids[i]\n",
    "        cidind = rfmtemp['custid'] == cidtemp\n",
    "        if np.any(cidind):\n",
    "            out[i, :] = np.array(rfmtemp.loc[cidind, ['r', 'f', 'm']]).reshape((1, 3))\n",
    "    if verbose: print ('took:', time.time()-t0)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getrfm_singletime(valdate, tgtcids, tgtskus, verbose = False):\n",
    "    '''\n",
    "    return (len(tgtcids), 1, len(tgtskus), 9)\n",
    "    where #(r, f, m) * #(rfmall, rfmcat, rfmthis) = 9\n",
    "    '''\n",
    "    x = getrfm(valdate, verbose = verbose)\n",
    "    if verbose: import time; print ('x shape')\n",
    "    # dissect the loaded file...\n",
    "    rfmall = x[0]\n",
    "    rfmcat = x[1]\n",
    "    # get indices for tgtskus...\n",
    "    tgtskusindices = np.where(np.in1d(allskus, tgtskus))[0]\n",
    "    \n",
    "    out = np.zeros((len(tgtcids), len(tgtskus), 3, 3))\n",
    "    rfmmall = getrfm_matrix(tgtcids, rfmall, verbose = verbose)\n",
    "    rfmmcat = getrfm_matrix(tgtcids, rfmcat, verbose = verbose)\n",
    "    \n",
    "    if verbose: t0 = time.time()\n",
    "    for k in range(len(tgtskus)):\n",
    "        out[:,k,0,:] = rfmmall\n",
    "        out[:,k,1,:] = rfmmcat\n",
    "        out[:,k,2,:] = getrfm_matrix(tgtcids, x[2+tgtskusindices[k]], verbose = verbose)\n",
    "    if verbose: print ('took:', time.time()-t0)\n",
    "    \n",
    "    return out.reshape((len(tgtcids), 1, len(tgtskus), 9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getdata(tgtcids, tgtskus, tgttimes, verbose = False):\n",
    "    '''\n",
    "    return array of shape (len(tgtcids), len(tgtskus), len(tgttimes), 13)\n",
    "    where #(tse,tte,unc,pcs) + #(r, f, m) * #(rfmall, rfmcat, rfmthis) = 13\n",
    "    '''\n",
    "    \n",
    "    outshape = (len(tgtcids), len(tgtskus), len(tgttimes), 13)\n",
    "    if verbose:\n",
    "        import time\n",
    "        t0 = time.time()\n",
    "        print ('outshape', outshape)\n",
    "        print ('max size in MB:', 32*np.prod(outshape)/np.power(10,6))\n",
    "    \n",
    "    resl_tstf = list(map(lambda x: formattedrow_allskus(x, tgtskus, tgttimes), tgtcids))\n",
    "    data_tstf = np.concatenate(resl_tstf, axis = 0)\n",
    "    if verbose: t1 = time.time(); print('tstf took', t1-t0); t0 = t1\n",
    "    \n",
    "    resl_rfm = list(map(lambda x: getrfm_singletime(x, tgtcids, tgtskus), tgttimes))\n",
    "    data_rfm = np.concatenate(resl_rfm, axis = 1)\n",
    "    if verbose: t1 = time.time(); print('rfm took', t1-t0); t0 = t1\n",
    "    \n",
    "    return np.concatenate((data_tstf, data_rfm), axis = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data = getdata(tgtcids, tgtskus, tgttimes, verbose = True)\n",
    "# print (data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchsize = 1000\n",
    "if testing: batchsize = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgtcids_split = np.array_split(tgtcids, np.ceil(float(len(tgtcids))/batchsize))\n",
    "print ('batchsize:%s, len split:%s' % (batchsize, len(tgtcids_split)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def worker(batchno):\n",
    "    fname = '%s/batchcache/%s.pkl%s' % (cwd, batchno, pklhp)\n",
    "    import time\n",
    "    t0 = time.time()\n",
    "    print ('batchno:', batchno)\n",
    "    out = getdata(tgtcids_split[batchno], tgtskus, tgttimes)\n",
    "    pickle.dump(out, gzip.open(fname, 'wb'), -1)\n",
    "    print ('batchno:%s took:%s' % (batchno, time.time()-t0))\n",
    "    print ('batchno:%s shape:%s' % (batchno, out.shape))\n",
    "    return fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "nthreads = 30\n",
    "if testing: nthreads = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if testing: out = worker(1); print (out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Pool(nthreads)\n",
    "import time; t0 = time.time()\n",
    "resl = p.map(worker, np.arange(len(tgtcids_split)))\n",
    "t1=time.time(); print('done in:', t1-t0); t0 = t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
